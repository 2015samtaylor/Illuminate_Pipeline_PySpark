{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from modules.auth import *\n",
    "from modules.assessments_endpoints import *\n",
    "from modules.frame_transformations import *\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from pyspark import RDD\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"API Request Parallelization\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "\n",
    "# Configure logging to use StreamHandler for stdout\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Adjust as needed (e.g., DEBUG, WARNING)\n",
    "    format=\"%(asctime)s - %(message)s\",  # Log format\n",
    "    datefmt=\"%d-%b-%y %H:%M:%S\",  # Date format\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)  # Direct logs to stdout\n",
    "    ],\n",
    "    force=True  # Ensures existing handlers are replaced\n",
    ")\n",
    "\n",
    "\n",
    "def get_assessment_results(spark, save_path, view_path, years_data, start_date, end_date_override=None):\n",
    "    logging.info('\\n\\n-------------New Illuminate Operations Logging Instance')\n",
    "\n",
    "    try:\n",
    "        access_token, expires_in = get_access_token()\n",
    "\n",
    "        assessments_df, assessment_id_list = get_all_assessments_metadata(access_token)\n",
    "        # assessment_id_list = assessment_id_list[:100] #for testing\n",
    "        missing_ids_from_metadata = ['114845', '141498'] # Add assessments that are not present in assessements metadata\n",
    "        assessment_id_list = list(set(assessment_id_list + missing_ids_from_metadata))\n",
    "        logging.info(f'Here is the length of the assessment_id_list variable {len(assessment_id_list)}')\n",
    "\n",
    "        test_results_group, log_results_group = parallel_get_assessment_scores(spark, access_token, assessment_id_list, 'Group', start_date, end_date_override=None)\n",
    "        test_results_standard, log_results_standard = parallel_get_assessment_scores(spark, access_token, assessment_id_list, 'Standard', start_date, end_date_override)\n",
    "        test_results_no_standard, log_results_no_standard = parallel_get_assessment_scores(spark, access_token, assessment_id_list, 'No_Standard', start_date, end_date_override)\n",
    " \n",
    "        test_results_combined = bring_together_test_results(test_results_no_standard, test_results_standard)\n",
    "        test_results_view = create_test_results_view(test_results_combined, years_data) #add in grade level col, string matching\n",
    "        logging.info(\"Assessment results fetched and processed.\")\n",
    "\n",
    "        \n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        if years_data == '23-24':\n",
    "            logging.info(f'Sending data for {years_data} school year')\n",
    "            send_to_local(save_path, test_results_group, 'assessment_results_group_historical.csv')\n",
    "            send_to_local(save_path, test_results_combined, 'assessment_results_combined_historical.csv')\n",
    "            send_to_local(view_path, test_results_view, 'illuminate_assessment_results_historical.csv')\n",
    "            \n",
    "        elif years_data == '24-25':\n",
    "            logging.info(f'Sending data for {years_data} school year')\n",
    "            send_to_local(save_path, test_results_group, 'assessment_results_group.csv')\n",
    "            send_to_local(save_path, test_results_combined, 'assessment_results_combined.csv')\n",
    "            send_to_local(view_path, test_results_view, 'illuminate_assessment_results.csv')\n",
    "        else:\n",
    "            raise ValueError(f'Unexpected value for years variable data {years_data}')\n",
    "        \n",
    "        #No matter what update assessments_metadata file to display available assessments\n",
    "        send_to_local(save_path, assessments_df, 'assessments_metadata.csv')\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching assessment results: {e}\")\n",
    "        raise AirflowException(\"Failed to fetch and process assessment results\")\n",
    "\n",
    "\n",
    "get_assessment_results(spark,\n",
    "                        save_path = '/home/g2015samtaylor/illuminate',\n",
    "                        view_path = '/home/g2015samtaylor/views',\n",
    "                        years_data = '23-24',\n",
    "                        start_date = '2023-07-01',\n",
    "                        end_date_override='2024-07-01')\n",
    "\n",
    "# end_date_override='2024-07-01' #should default to todays date\n",
    "\n",
    "\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/sam/icef-437920.json\"\n",
    "\n",
    "\n",
    "#Add to requirements.txt\n",
    "#Re-initaite docker with new tag of spark, in case need to roll back\n",
    "#Update changes in docker file\n",
    "#Make sure changes flow through to airflow\n",
    "#Run locally for string matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traceback (most recent call last):\n",
    "#   File \"/app/illuminate_pipeline.py\", line 43, in get_assessment_results\n",
    "#     test_results_view = create_test_results_view(test_results_combined, years_data)\n",
    "#   File \"/app/modules/frame_transformations.py\", line 180, in create_test_results_view\n",
    "#     test_results_view = apply_manual_changes(test_results)\n",
    "# TypeError: apply_manual_changes() missing 1 required positional argument: 'changes_file_path'\n",
    "\n",
    "# During handling of the above exception, another exception occurred:\n",
    "\n",
    "# Traceback (most recent call last):\n",
    "#   File \"/app/illuminate_pipeline.py\", line 69, in <module>\n",
    "#     get_assessment_results(spark,\n",
    "#   File \"/app/illuminate_pipeline.py\", line 66, in get_assessment_results\n",
    "#     raise AirflowException(\"Failed to fetch and process assessment results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/git_directory/ICEF/Illuminate/venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1933: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/sam/icef-437920.json\"\n",
    "    \n",
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client(project='icef-437920')\n",
    "\n",
    "\n",
    "\n",
    "# Execute the query\n",
    "changes = client.query('''\n",
    "SELECT \n",
    "CAST(assessment_id AS STRING) AS assessment_id, \n",
    "* EXCEPT(assessment_id) \n",
    "FROM `icef-437920.illuminate.illuminate_checkpoint_title_issues`\n",
    "''')\n",
    "\n",
    "\n",
    "# Convert the query results to a Pandas DataFrame\n",
    "changes = changes.result().to_dataframe()\n",
    "\n",
    "update_dict = changes.set_index('assessment_id')['assessment_id'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from google.cloud import storage\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/sam/icef-437920.json\"\n",
    "test = pd.read_csv('/home/sam/git_directory/ICEF/Illuminate/test.csv')\n",
    "\n",
    "def send_to_gcs(bucket_name, save_path, frame, frame_name):\n",
    "    \"\"\"\n",
    "    Uploads a DataFrame as a CSV file to a GCS bucket.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the GCS bucket.\n",
    "        save_path (str): The path within the bucket where the file will be saved.\n",
    "        frame (pd.DataFrame): The DataFrame to upload.\n",
    "        frame_name (str): The name of the file to save.\n",
    "    \"\"\"\n",
    "    if not frame.empty:\n",
    "        # Initialize the GCS client\n",
    "        client = storage.Client()\n",
    "\n",
    "        # Create a temporary local file to save the DataFrame\n",
    "        temp_file_path = os.path.join(\"/tmp\", frame_name)\n",
    "        frame.to_csv(temp_file_path, index=False)\n",
    "\n",
    "        try:\n",
    "            # Get the bucket\n",
    "            bucket = client.bucket(bucket_name)\n",
    "\n",
    "            # Define the blob (file path in the bucket)\n",
    "            blob = bucket.blob(os.path.join(save_path, frame_name))\n",
    "\n",
    "            # Upload the file to GCS\n",
    "            blob.upload_from_filename(temp_file_path)\n",
    "            logging.info(f\"{frame_name} uploaded to GCS bucket {bucket_name} at {save_path}/{frame_name}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to upload {frame_name} to GCS bucket {bucket_name}: {e}\")\n",
    "        finally:\n",
    "            # Clean up the temporary file\n",
    "            if os.path.exists(temp_file_path):\n",
    "                os.remove(temp_file_path)\n",
    "    else:\n",
    "        logging.info(f\"No data present in {frame_name} file\")\n",
    "\n",
    "send_to_gcs(\n",
    "        bucket_name=\"illuminatebucket-icefschools-1\",\n",
    "        save_path=\"\",\n",
    "        frame=test,\n",
    "        frame_name=\"test.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assessment_id</th>\n",
       "      <th>test_type</th>\n",
       "      <th>curriculum</th>\n",
       "      <th>unit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62474</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>Math</td>\n",
       "      <td>6.NS.A.1</td>\n",
       "      <td>6.NS.A.1 Checkpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142420</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>Math</td>\n",
       "      <td>6.NS.C.5-7</td>\n",
       "      <td>Grade 6 NS.C.5-7 Checkpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62479</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>Math</td>\n",
       "      <td>6.RP.A.2</td>\n",
       "      <td>6.RP.A.2 Checkpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62525</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>Math</td>\n",
       "      <td>6.RP.A.3a</td>\n",
       "      <td>6.RP.A.3a Checkpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62477</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>Math</td>\n",
       "      <td>6.RP.A.3b</td>\n",
       "      <td>6.RP.A.3b Checkpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>107735</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>Math</td>\n",
       "      <td>Unit 5 Section B</td>\n",
       "      <td>Grade K Math Unit 5 Section B Checkpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>107670</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>Math</td>\n",
       "      <td>Unit 5 Section C</td>\n",
       "      <td>Grade 3 Math Unit 5 Section C Checkpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>107526</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>Math</td>\n",
       "      <td>Unit 6 Section A</td>\n",
       "      <td>Grade 2 Math Unit 6 Section A Checkpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>115933</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>Math</td>\n",
       "      <td>Unit 6 Section A</td>\n",
       "      <td>Grade K Math Unit 6 Section A Checkpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>107528</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>Math</td>\n",
       "      <td>Unit 6 Section C</td>\n",
       "      <td>Grade 2 Math Unit 6 Section C Checkpoint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   assessment_id   test_type curriculum              unit  \\\n",
       "0          62474  checkpoint       Math          6.NS.A.1   \n",
       "1         142420  checkpoint       Math        6.NS.C.5-7   \n",
       "2          62479  checkpoint       Math          6.RP.A.2   \n",
       "3          62525  checkpoint       Math        6.RP.A.3a    \n",
       "4          62477  checkpoint       Math        6.RP.A.3b    \n",
       "..           ...         ...        ...               ...   \n",
       "76        107735  checkpoint       Math  Unit 5 Section B   \n",
       "77        107670  checkpoint       Math  Unit 5 Section C   \n",
       "78        107526  checkpoint       Math  Unit 6 Section A   \n",
       "79        115933  checkpoint       Math  Unit 6 Section A   \n",
       "80        107528  checkpoint       Math  Unit 6 Section C   \n",
       "\n",
       "                                       title  \n",
       "0                        6.NS.A.1 Checkpoint  \n",
       "1                Grade 6 NS.C.5-7 Checkpoint  \n",
       "2                        6.RP.A.2 Checkpoint  \n",
       "3                       6.RP.A.3a Checkpoint  \n",
       "4                       6.RP.A.3b Checkpoint  \n",
       "..                                       ...  \n",
       "76  Grade K Math Unit 5 Section B Checkpoint  \n",
       "77  Grade 3 Math Unit 5 Section C Checkpoint  \n",
       "78  Grade 2 Math Unit 6 Section A Checkpoint  \n",
       "79  Grade K Math Unit 6 Section A Checkpoint  \n",
       "80  Grade 2 Math Unit 6 Section C Checkpoint  \n",
       "\n",
       "[81 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'update_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mupdate_dict\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'update_dict' is not defined"
     ]
    }
   ],
   "source": [
    "update_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   File \"/app/illuminate_pipeline.py\", line 43, in get_assessment_results\n",
    "#     test_results_view = create_test_results_view(test_results_combined, years_data)\n",
    "#   File \"/app/modules/frame_transformations.py\", line 180, in create_test_results_view\n",
    "#     test_results_view = apply_manual_changes(test_results)\n",
    "#   File \"/app/modules/frame_transformations.py\", line 168, in apply_manual_changes\n",
    "#     update_dict = changes.set_index('assessment_id')[column].to_dict()\n",
    "# AttributeError: 'QueryJob' object has no attribute 'set_index'\n",
    "\n",
    "# During handling of the above exception, another exception occurred:\n",
    "\n",
    "# Traceback (most recent call last):\n",
    "#   File \"/app/illuminate_pipeline.py\", line 69, in <module>\n",
    "#     get_assessment_results(spark,\n",
    "#   File \"/app/illuminate_pipeline.py\", line 66, in get_assessment_results\n",
    "#     raise AirflowException(\"Failed to fetch and process assessment results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
