{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/13 18:31:34 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "25/01/13 18:31:34 INFO SharedState: Warehouse path is 'file:/home/g2015samtaylor/airflow/git_directory/Illuminate/spark-warehouse'.\n",
      "25/01/13 18:31:35 INFO BlockManagerInfo: Removed broadcast_1_piece0 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 3.9 KiB, free: 366.3 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-Jan-25 18:31:36 - \n",
      "\n",
      "-------------New Illuminate Operations Logging Instance\n",
      "13-Jan-25 18:31:36 - Calling API token endpoint\n",
      "13-Jan-25 18:31:36 - Succesfully retrieved API token\n",
      "13-Jan-25 18:31:36 - Fetching data from https://icefps.illuminateed.com/live/rest_server.php/Api/Assessments/?page=1&limit=1000\n",
      "13-Jan-25 18:31:36 - Here is the total num of pages on this endpoint 2\n",
      "13-Jan-25 18:31:36 - Fetching data from https://icefps.illuminateed.com/live/rest_server.php/Api/Assessments/?page=2&limit=1000\n",
      "13-Jan-25 18:31:36 - Here is the total num of pages on this endpoint 2\n",
      "13-Jan-25 18:31:36 - Looped through 2 pages. Results for func get_all_assessments_metadata output into DataFrame\n",
      "13-Jan-25 18:31:36 - Here is the length of the assessment_id_list variable 1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/13 18:31:37 INFO SparkContext: Starting job: collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226\n",
      "25/01/13 18:31:37 INFO DAGScheduler: Got job 2 (collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226) with 4 output partitions\n",
      "25/01/13 18:31:37 INFO DAGScheduler: Final stage: ResultStage 2 (collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226)\n",
      "25/01/13 18:31:37 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/13 18:31:37 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/13 18:31:37 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[5] at collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226), which has no missing parents\n",
      "25/01/13 18:31:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.2 KiB, free 366.3 MiB)\n",
      "25/01/13 18:31:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.9 KiB, free 366.3 MiB)\n",
      "25/01/13 18:31:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 3.9 KiB, free: 366.3 MiB)\n",
      "25/01/13 18:31:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/13 18:31:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 2 (PythonRDD[5] at collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "25/01/13 18:31:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 4 tasks resource profile 0\n",
      "25/01/13 18:31:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 8) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 0, PROCESS_LOCAL, 11333 bytes) \n",
      "25/01/13 18:31:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 9) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 1, PROCESS_LOCAL, 11347 bytes) \n",
      "25/01/13 18:31:37 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 10) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 2, PROCESS_LOCAL, 11330 bytes) \n",
      "25/01/13 18:31:37 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 11) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 3, PROCESS_LOCAL, 11337 bytes) \n",
      "25/01/13 18:31:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 8)\n",
      "25/01/13 18:31:37 INFO Executor: Running task 2.0 in stage 2.0 (TID 10)\n",
      "25/01/13 18:31:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 9)\n",
      "25/01/13 18:31:37 INFO Executor: Running task 3.0 in stage 2.0 (TID 11)\n",
      "Exception in thread \"serve RDD 3\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.net.PlainSocketImpl.socketAccept(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409)\n",
      "\tat java.net.ServerSocket.implAccept(ServerSocket.java:560)\n",
      "\tat java.net.ServerSocket.accept(ServerSocket.java:528)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:65)\n",
      "25/01/13 18:32:57 INFO PythonRunner: Times: total = 80692, boot = -8530, init = 8556, finish = 80666\n",
      "25/01/13 18:32:57 INFO MemoryStore: Block taskresult_11 stored as bytes in memory (estimated size 3.9 MiB, free 362.4 MiB)\n",
      "25/01/13 18:32:57 INFO BlockManagerInfo: Added taskresult_11 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 3.9 MiB, free: 362.4 MiB)\n",
      "25/01/13 18:32:57 INFO Executor: Finished task 3.0 in stage 2.0 (TID 11). 4044834 bytes result sent via BlockManager)\n",
      "25/01/13 18:32:57 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 11) in 80771 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (1/4)\n",
      "25/01/13 18:32:57 INFO BlockManagerInfo: Removed taskresult_11 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 3.9 MiB, free: 366.3 MiB)\n",
      "25/01/13 18:32:58 INFO PythonRunner: Times: total = 81235, boot = -8625, init = 8627, finish = 81233\n",
      "25/01/13 18:32:58 INFO MemoryStore: Block taskresult_10 stored as bytes in memory (estimated size 3.3 MiB, free 363.0 MiB)\n",
      "25/01/13 18:32:58 INFO BlockManagerInfo: Added taskresult_10 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 3.3 MiB, free: 363.0 MiB)\n",
      "25/01/13 18:32:58 INFO Executor: Finished task 2.0 in stage 2.0 (TID 10). 3448028 bytes result sent via BlockManager)\n",
      "25/01/13 18:32:58 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 10) in 81407 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (2/4)\n",
      "25/01/13 18:32:58 INFO BlockManagerInfo: Removed taskresult_10 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 3.3 MiB, free: 366.3 MiB)\n",
      "25/01/13 18:32:58 INFO PythonRunner: Times: total = 81788, boot = -8269, init = 8284, finish = 81773\n",
      "25/01/13 18:32:58 INFO MemoryStore: Block taskresult_8 stored as bytes in memory (estimated size 3.0 MiB, free 363.3 MiB)\n",
      "25/01/13 18:32:58 INFO BlockManagerInfo: Added taskresult_8 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 3.0 MiB, free: 363.3 MiB)\n",
      "25/01/13 18:32:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 8). 3099454 bytes result sent via BlockManager)\n",
      "25/01/13 18:32:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 8) in 81871 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (3/4)\n",
      "25/01/13 18:32:58 INFO BlockManagerInfo: Removed taskresult_8 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 3.0 MiB, free: 366.3 MiB)\n",
      "25/01/13 18:32:59 INFO PythonRunner: Times: total = 82596, boot = -8106, init = 8119, finish = 82583\n",
      "25/01/13 18:32:59 INFO MemoryStore: Block taskresult_9 stored as bytes in memory (estimated size 4.1 MiB, free 362.2 MiB)\n",
      "25/01/13 18:32:59 INFO BlockManagerInfo: Added taskresult_9 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 4.1 MiB, free: 362.2 MiB)\n",
      "25/01/13 18:32:59 INFO Executor: Finished task 1.0 in stage 2.0 (TID 9). 4325315 bytes result sent via BlockManager)\n",
      "25/01/13 18:32:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 9) in 82674 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (4/4)\n",
      "25/01/13 18:32:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "25/01/13 18:32:59 INFO DAGScheduler: ResultStage 2 (collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226) finished in 82.694 s\n",
      "25/01/13 18:32:59 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/13 18:32:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "25/01/13 18:32:59 INFO DAGScheduler: Job 2 finished: collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226, took 82.700903 s\n",
      "25/01/13 18:32:59 INFO BlockManagerInfo: Removed taskresult_9 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 4.1 MiB, free: 366.3 MiB)\n",
      "25/01/13 18:33:00 INFO SparkContext: Starting job: collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226\n",
      "25/01/13 18:33:00 INFO DAGScheduler: Got job 3 (collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226) with 4 output partitions\n",
      "25/01/13 18:33:00 INFO DAGScheduler: Final stage: ResultStage 3 (collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226)\n",
      "25/01/13 18:33:00 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/13 18:33:00 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/13 18:33:00 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[7] at collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226), which has no missing parents\n",
      "25/01/13 18:33:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.2 KiB, free 366.3 MiB)\n",
      "25/01/13 18:33:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KiB, free 366.3 MiB)\n",
      "25/01/13 18:33:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 3.9 KiB, free: 366.3 MiB)\n",
      "25/01/13 18:33:00 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/13 18:33:00 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 3 (PythonRDD[7] at collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "25/01/13 18:33:00 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks resource profile 0\n",
      "25/01/13 18:33:00 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 12) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 0, PROCESS_LOCAL, 11333 bytes) \n",
      "25/01/13 18:33:00 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 13) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 1, PROCESS_LOCAL, 11347 bytes) \n",
      "25/01/13 18:33:00 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 14) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 2, PROCESS_LOCAL, 11330 bytes) \n",
      "25/01/13 18:33:00 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 15) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 3, PROCESS_LOCAL, 11337 bytes) \n",
      "25/01/13 18:33:00 INFO Executor: Running task 0.0 in stage 3.0 (TID 12)\n",
      "25/01/13 18:33:00 INFO Executor: Running task 2.0 in stage 3.0 (TID 14)\n",
      "25/01/13 18:33:00 INFO Executor: Running task 1.0 in stage 3.0 (TID 13)\n",
      "25/01/13 18:33:00 INFO Executor: Running task 3.0 in stage 3.0 (TID 15)\n",
      "25/01/13 18:34:24 INFO PythonRunner: Times: total = 83707, boot = -859, init = 866, finish = 83700\n",
      "25/01/13 18:34:24 INFO MemoryStore: Block taskresult_14 stored as bytes in memory (estimated size 11.3 MiB, free 354.9 MiB)\n",
      "25/01/13 18:34:24 INFO BlockManagerInfo: Added taskresult_14 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 11.3 MiB, free: 355.0 MiB)\n",
      "25/01/13 18:34:24 INFO Executor: Finished task 2.0 in stage 3.0 (TID 14). 11883198 bytes result sent via BlockManager)\n",
      "25/01/13 18:34:24 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 14) in 83829 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (1/4)\n",
      "25/01/13 18:34:24 INFO BlockManagerInfo: Removed taskresult_14 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 11.3 MiB, free: 366.3 MiB)\n",
      "25/01/13 18:34:24 INFO PythonRunner: Times: total = 83917, boot = -2776, init = 2778, finish = 83915\n",
      "25/01/13 18:34:24 INFO MemoryStore: Block taskresult_12 stored as bytes in memory (estimated size 6.6 MiB, free 359.7 MiB)\n",
      "25/01/13 18:34:24 INFO BlockManagerInfo: Added taskresult_12 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 6.6 MiB, free: 359.7 MiB)\n",
      "25/01/13 18:34:24 INFO Executor: Finished task 0.0 in stage 3.0 (TID 12). 6897044 bytes result sent via BlockManager)\n",
      "25/01/13 18:34:24 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 12) in 83988 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (2/4)\n",
      "25/01/13 18:34:24 INFO BlockManagerInfo: Removed taskresult_12 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 6.6 MiB, free: 366.3 MiB)\n",
      "25/01/13 18:34:25 INFO PythonRunner: Times: total = 84561, boot = -1672, init = 1677, finish = 84556\n",
      "25/01/13 18:34:25 INFO MemoryStore: Block taskresult_13 stored as bytes in memory (estimated size 13.4 MiB, free 352.9 MiB)\n",
      "25/01/13 18:34:25 INFO BlockManagerInfo: Added taskresult_13 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 13.4 MiB, free: 352.9 MiB)\n",
      "25/01/13 18:34:25 INFO Executor: Finished task 1.0 in stage 3.0 (TID 13). 14040255 bytes result sent via BlockManager)\n",
      "25/01/13 18:34:25 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 13) in 84644 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (3/4)\n",
      "25/01/13 18:34:25 INFO BlockManagerInfo: Removed taskresult_13 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 13.4 MiB, free: 366.3 MiB)\n",
      "25/01/13 18:34:36 INFO PythonRunner: Times: total = 95841, boot = -2227, init = 2242, finish = 95826\n",
      "25/01/13 18:34:36 INFO MemoryStore: Block taskresult_15 stored as bytes in memory (estimated size 11.8 MiB, free 354.5 MiB)\n",
      "25/01/13 18:34:36 INFO BlockManagerInfo: Added taskresult_15 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 11.8 MiB, free: 354.5 MiB)\n",
      "25/01/13 18:34:36 INFO Executor: Finished task 3.0 in stage 3.0 (TID 15). 12341824 bytes result sent via BlockManager)\n",
      "25/01/13 18:34:36 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 15) in 95943 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (4/4)\n",
      "25/01/13 18:34:36 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "25/01/13 18:34:36 INFO BlockManagerInfo: Removed taskresult_15 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 11.8 MiB, free: 366.3 MiB)\n",
      "25/01/13 18:34:36 INFO DAGScheduler: ResultStage 3 (collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226) finished in 95.958 s\n",
      "25/01/13 18:34:36 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/13 18:34:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "25/01/13 18:34:36 INFO DAGScheduler: Job 3 finished: collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226, took 95.966814 s\n",
      "25/01/13 18:34:37 INFO SparkContext: Starting job: collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226\n",
      "25/01/13 18:34:37 INFO DAGScheduler: Got job 4 (collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226) with 4 output partitions\n",
      "25/01/13 18:34:37 INFO DAGScheduler: Final stage: ResultStage 4 (collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226)\n",
      "25/01/13 18:34:37 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/13 18:34:37 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/13 18:34:37 INFO DAGScheduler: Submitting ResultStage 4 (PythonRDD[9] at collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226), which has no missing parents\n",
      "25/01/13 18:34:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.2 KiB, free 366.3 MiB)\n",
      "25/01/13 18:34:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.9 KiB, free 366.3 MiB)\n",
      "25/01/13 18:34:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 3.9 KiB, free: 366.3 MiB)\n",
      "25/01/13 18:34:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/13 18:34:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 4 (PythonRDD[9] at collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "25/01/13 18:34:37 INFO TaskSchedulerImpl: Adding task set 4.0 with 4 tasks resource profile 0\n",
      "25/01/13 18:34:37 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 16) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 0, PROCESS_LOCAL, 11333 bytes) \n",
      "25/01/13 18:34:37 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 17) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 1, PROCESS_LOCAL, 11347 bytes) \n",
      "25/01/13 18:34:37 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 18) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 2, PROCESS_LOCAL, 11330 bytes) \n",
      "25/01/13 18:34:37 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 19) (icef-instance-2.us-west2-a.c.icef-437920.internal, executor driver, partition 3, PROCESS_LOCAL, 11337 bytes) \n",
      "25/01/13 18:34:37 INFO Executor: Running task 0.0 in stage 4.0 (TID 16)\n",
      "25/01/13 18:34:37 INFO Executor: Running task 1.0 in stage 4.0 (TID 17)\n",
      "25/01/13 18:34:37 INFO Executor: Running task 3.0 in stage 4.0 (TID 19)\n",
      "25/01/13 18:34:37 INFO Executor: Running task 2.0 in stage 4.0 (TID 18)\n",
      "25/01/13 18:36:01 INFO PythonRunner: Times: total = 83947, boot = -1034, init = 1037, finish = 83944\n",
      "25/01/13 18:36:01 INFO Executor: Finished task 0.0 in stage 4.0 (TID 16). 1043457 bytes result sent to driver\n",
      "25/01/13 18:36:01 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 16) in 83981 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (1/4)\n",
      "25/01/13 18:36:01 INFO PythonRunner: Times: total = 84204, boot = -12298, init = 12314, finish = 84188\n",
      "25/01/13 18:36:01 INFO MemoryStore: Block taskresult_18 stored as bytes in memory (estimated size 1397.4 KiB, free 364.9 MiB)\n",
      "25/01/13 18:36:01 INFO BlockManagerInfo: Added taskresult_18 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 1397.4 KiB, free: 364.9 MiB)\n",
      "25/01/13 18:36:01 INFO Executor: Finished task 2.0 in stage 4.0 (TID 18). 1430978 bytes result sent via BlockManager)\n",
      "25/01/13 18:36:01 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 18) in 84237 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (2/4)\n",
      "25/01/13 18:36:01 INFO BlockManagerInfo: Removed taskresult_18 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 1397.4 KiB, free: 366.3 MiB)\n",
      "25/01/13 18:36:02 INFO PythonRunner: Times: total = 85422, boot = -13151, init = 13154, finish = 85419\n",
      "25/01/13 18:36:02 INFO MemoryStore: Block taskresult_17 stored as bytes in memory (estimated size 1469.7 KiB, free 364.8 MiB)\n",
      "25/01/13 18:36:02 INFO BlockManagerInfo: Added taskresult_17 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 1469.7 KiB, free: 364.8 MiB)\n",
      "25/01/13 18:36:02 INFO Executor: Finished task 1.0 in stage 4.0 (TID 17). 1504982 bytes result sent via BlockManager)\n",
      "25/01/13 18:36:02 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 17) in 85453 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (3/4)\n",
      "25/01/13 18:36:02 INFO BlockManagerInfo: Removed taskresult_17 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 1469.7 KiB, free: 366.3 MiB)\n",
      "25/01/13 18:36:03 INFO PythonRunner: Times: total = 85814, boot = -12947, init = 12955, finish = 85806\n",
      "25/01/13 18:36:03 INFO MemoryStore: Block taskresult_19 stored as bytes in memory (estimated size 1530.0 KiB, free 364.8 MiB)\n",
      "25/01/13 18:36:03 INFO BlockManagerInfo: Added taskresult_19 in memory on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 (size: 1530.0 KiB, free: 364.8 MiB)\n",
      "25/01/13 18:36:03 INFO Executor: Finished task 3.0 in stage 4.0 (TID 19). 1566716 bytes result sent via BlockManager)\n",
      "25/01/13 18:36:03 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 19) in 85847 ms on icef-instance-2.us-west2-a.c.icef-437920.internal (executor driver) (4/4)\n",
      "25/01/13 18:36:03 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "25/01/13 18:36:03 INFO DAGScheduler: ResultStage 4 (collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226) finished in 85.861 s\n",
      "25/01/13 18:36:03 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/13 18:36:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished\n",
      "25/01/13 18:36:03 INFO DAGScheduler: Job 4 finished: collect at /home/g2015samtaylor/airflow/git_directory/Illuminate/modules/assessments_endpoints.py:226, took 85.867611 s\n",
      "25/01/13 18:36:03 INFO BlockManagerInfo: Removed taskresult_19 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 1530.0 KiB, free: 366.3 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-Jan-25 18:36:09 - Assessment results fetched and processed.\n",
      "13-Jan-25 18:36:09 - Sending data for 23-24 school year\n",
      "13-Jan-25 18:36:10 - assessment_results_group_historical.csv saved to /home/g2015samtaylor/illuminate\n",
      "13-Jan-25 18:36:12 - assessment_results_combined_historical.csv saved to /home/g2015samtaylor/illuminate\n",
      "13-Jan-25 18:36:14 - illuminate_assessment_results_historical.csv saved to /home/g2015samtaylor/views\n",
      "13-Jan-25 18:36:14 - assessments_metadata.csv saved to /home/g2015samtaylor/illuminate\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from modules.auth import *\n",
    "from modules.assessments_endpoints import *\n",
    "from modules.frame_transformations import *\n",
    "from modules.config import base_url_illuminate\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from pyspark import RDD\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"API Request Parallelization\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "\n",
    "# Configure logging to use StreamHandler for stdout\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Adjust as needed (e.g., DEBUG, WARNING)\n",
    "    format=\"%(asctime)s - %(message)s\",  # Log format\n",
    "    datefmt=\"%d-%b-%y %H:%M:%S\",  # Date format\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)  # Direct logs to stdout\n",
    "    ],\n",
    "    force=True  # Ensures existing handlers are replaced\n",
    ")\n",
    "\n",
    "\n",
    "def get_assessment_results(spark, save_path, view_path, years_data, start_date, end_date_override=None):\n",
    "    logging.info('\\n\\n-------------New Illuminate Operations Logging Instance')\n",
    "\n",
    "    try:\n",
    "        access_token, expires_in = get_access_token()\n",
    "\n",
    "        assessments_df, assessment_id_list = get_all_assessments_metadata(access_token)\n",
    "        # assessment_id_list = assessment_id_list[:100] #for testing\n",
    "        missing_ids_from_metadata = ['114845', '141498'] # Add assessments that are not present in assessements metadata\n",
    "        assessment_id_list = list(set(assessment_id_list + missing_ids_from_metadata))\n",
    "        logging.info(f'Here is the length of the assessment_id_list variable {len(assessment_id_list)}')\n",
    "\n",
    "        test_results_group, log_results_group = parallel_get_assessment_scores(spark, access_token, assessment_id_list, 'Group', start_date, end_date_override=None)\n",
    "        test_results_standard, log_results_standard = parallel_get_assessment_scores(spark, access_token, assessment_id_list, 'Standard', start_date, end_date_override)\n",
    "        test_results_no_standard, log_results_no_standard = parallel_get_assessment_scores(spark, access_token, assessment_id_list, 'No_Standard', start_date, end_date_override)\n",
    " \n",
    "        test_results_combined = bring_together_test_results(test_results_no_standard, test_results_standard)\n",
    "        test_results_view = create_test_results_view(test_results_combined, years_data) #add in grade level col, string matching\n",
    "        logging.info(\"Assessment results fetched and processed.\")\n",
    "\n",
    "        \n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        if years_data == '23-24':\n",
    "            logging.info(f'Sending data for {years_data} school year')\n",
    "            send_to_local(save_path, test_results_group, 'assessment_results_group_historical.csv')\n",
    "            send_to_local(save_path, test_results_combined, 'assessment_results_combined_historical.csv')\n",
    "            send_to_local(view_path, test_results_view, 'illuminate_assessment_results_historical.csv')\n",
    "            \n",
    "        elif years_data == '24-25':\n",
    "            logging.info(f'Sending data for {years_data} school year')\n",
    "            send_to_local(save_path, test_results_group, 'assessment_results_group.csv')\n",
    "            send_to_local(save_path, test_results_combined, 'assessment_results_combined.csv')\n",
    "            send_to_local(view_path, test_results_view, 'illuminate_assessment_results.csv')\n",
    "        else:\n",
    "            raise ValueError(f'Unexpected value for years variable data {years_data}')\n",
    "        \n",
    "        #No matter what update assessments_metadata file to display available assessments\n",
    "        send_to_local(save_path, assessments_df, 'assessments_metadata.csv')\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching assessment results: {e}\")\n",
    "        raise AirflowException(\"Failed to fetch and process assessment results\")\n",
    "\n",
    "\n",
    "get_assessment_results(spark,\n",
    "                        save_path = '/home/g2015samtaylor/illuminate',\n",
    "                        view_path = '/home/g2015samtaylor/views',\n",
    "                        years_data = '23-24',\n",
    "                        start_date = '2023-07-01',\n",
    "                        end_date_override='2024-07-01')\n",
    "\n",
    "# end_date_override='2024-07-01' #should default to todays date\n",
    "\n",
    "\n",
    "\n",
    "#Create spark session in main script\n",
    "#Merge branch with main for feauture enhancement practice. \n",
    "\n",
    "#Add to requirements.txt\n",
    "#Re-initaite docker with new tag of spark, in case need to roll back\n",
    "#Update changes in docker file\n",
    "#Make sure changes flow through to airflow\n",
    "#Run locally for string matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "13-Jan-25 18:40:48 - Calling API token endpoint\n",
      "13-Jan-25 18:40:48 - Succesfully retrieved API token\n",
      "The length of the v frame is 103458 rows\n",
      "the length after the merge is 103458 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/13 19:01:03 INFO BlockManagerInfo: Removed broadcast_0_piece0 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 3.9 KiB, free: 366.3 MiB)\n",
      "25/01/13 19:01:03 INFO BlockManagerInfo: Removed broadcast_4_piece0 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 3.9 KiB, free: 366.3 MiB)\n",
      "25/01/13 19:01:03 INFO BlockManagerInfo: Removed broadcast_3_piece0 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 3.9 KiB, free: 366.3 MiB)\n",
      "25/01/13 19:01:03 INFO BlockManagerInfo: Removed broadcast_2_piece0 on icef-instance-2.us-west2-a.c.icef-437920.internal:34901 in memory (size: 3.9 KiB, free: 366.3 MiB)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from modules.auth import *\n",
    "from modules.assessments_endpoints import *\n",
    "from modules.frame_transformations import *\n",
    "from modules.config import base_url_illuminate\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from modules.frame_transformations import *\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "path_fixes_file = '/home/g2015samtaylor/airflow/git_directory/Illuminate/modules/illuminate_historical_column_fixes_2324.csv'\n",
    "historical_view_path = '/home/g2015samtaylor/views/illuminate_assessment_results_historical.csv'\n",
    "access_token, expires_in = get_access_token()\n",
    "\n",
    "fixes = pd.read_csv(path_fixes_file)\n",
    "v = pd.read_csv(historical_view_path) \n",
    "\n",
    "h = fix_historical_columns(access_token, path_fixes_file, historical_view_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_view_path = '/home/g2015samtaylor/views/illuminate_assessment_results_historical.csv'\n",
    "\n",
    "v = pd.read_csv(historical_view_path) \n",
    "#The length of v prior to new raw file is "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
